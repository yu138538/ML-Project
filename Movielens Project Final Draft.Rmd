---
title: "MovieLens Project"
Author: "Nick Ray"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

# 1. Introduction

This report is an analysis of the *MovieLens* data set which contains 10 million records of the reviews of more than 10,000 movie titles by approximately 70,000 users.  The analysis attempts to predict the rating that a user would give for a movie given a movie title's average rating and the average rating of all movies submitted by a given user. 

Three different **linear regression** models are used to train and predict movie ratings. The first model compares actual ratings to the overall average movie rating (*mu_hat*) of approximately 3.5. The second model, in addition to the overall average, incorporates the average rating of each movie  title and compares the predicted (fitted) results to the actual results. The third model augments the second model by adding the average movie ratings by user. 

The models are tested using validation (training) sets containing 10% and 25% of the records of the original data set. The third model incorporating average ratings by users, included only those users submitting 100 ratings or more. The RMSE, Root Mean Squared Error, yielded smaller values with each successive model, suggesting greater model accuracy as a result. 

The third model, based on movieID and userID and using a validation set of 10% of the original data, yields an RMSE of **0.86440**.

The source of the MovieLens data set may be extracted from the following links:

 https://grouplens.org/datasets/movielens/10m/  \
 http://files.grouplens.org/datasets/movielens/ml-10m.zip
 
 The Github link for the PDF, R and RMD files can be found here: 
 
 https://github.com/yu138538/ML-Project



# 2. Analysis

```{r Source Info, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)


################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

# if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
# if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
# if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip
```



```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(data.table)
library(readxl)
library(knitr)
library(kableExtra)

options(pillar.sigfig = 5)


#Download Movielens dataset
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")
```
## 2.1 The *MovieLens* Data set

The data set used for the analysis consists of 10 million rows, one row per movie review, and six variables. The analysis attempts to predict **rating** of each movie review.

##### The structure of the *MovieLens* data

```{r inspect data, echo=FALSE}
#Inspect the Movielens data
movielens %>% glimpse() 

movielens %>% 
  summarise(n_users=n_distinct(userId),
            n_movies=n_distinct(movieId))
```

##### Histogram of the counts of movies rated
```{r Hist 1, echo=FALSE}
movielens %>% 
  group_by(movieId) %>% 
  summarise( n=n()) %>% 
  ggplot(aes(x=n))+
  geom_histogram(color="black",fill="grey")+
  scale_x_continuous(trans='log10')+
  ggtitle("Movies")
```

##### Histogram of the echo of user ratings

```{r Hist 2, echo=FALSE}
movielens %>% 
  group_by(userId) %>% 
  summarise( n=n()) %>% 
  ggplot(aes(x=n,title="Users"))+
  geom_histogram(color="black",fill="light blue")+
  scale_x_continuous(trans='log10')+
  ggtitle("Users")

```


The Validation set used for testing is 10% of the original data or approximately 2.5 million records.

```{r Validation set, echo=FALSE}
# Validation set will be 25% of MovieLens data

 set.seed(999)

test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.10, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

  rm(dl, ratings, movies, test_index, temp, movielens, removed)
 
 RMSE <- function(true_ratings,predicted_ratings){
   sqrt(mean((true_ratings-predicted_ratings)^2))
 }


```

##### A preview of the Training Data Set


```{r Training set, echo=FALSE}
#----------------
# head(edx) 
edx %>% glimpse() 
```

The training set used to build the regression model, contains the remaining 75% of the data, or 7.5 million records.

##### A preview of the Testing Data Set


```{r Test set, echo=FALSE}
# head(validation)
 validation%>% glimpse() 

# write.csv(edx,file="EDX - Train.csv",col.names=TRUE)
# write.csv(validation,file="Validation - Test.csv",col.names=TRUE)

#-------
# Movie effect Model: Mu plus Movie factor

train_set <- edx
test_set <- validation

```

Both the validation and training data sets are filtered to remove blank movie and user ID numbers as demonstrated by the semi-joins in the original R code.


The accuracy of models used in the analysis are measured using the *RMSE*, *Root Mean Square Error* defined as 

$$\ RMSE=\sqrt{\frac{1}{N}\sum_{u,i}(\hat{y}_u,_i -y_u,_i)^2}$$

where 
$$\hat{y}_u,_i$$
is the predicted rating as fitted by the regression model.

And $$y_u,_i$$
is the actual value. The objective of the analysis is to minimise the value of *RMSE*.

The analysis of the *MovieLens* data is done using three different Linear Regression models.


## 2.2 The Overall Average Rating for all Movie Titles

The average rating for all movies submitted by all users is simply the arithmetic mean of all ratings.

$$\ Y_u,_i =\mu+ \varepsilon_u,_i $$

where $$\varepsilon_u,_i$$
is the randomly distributed error.


The average rating across all movies in the data set is
```{r Movie factor, echo=FALSE}
#Ave across all movies: mu_hat
mu <- mean(train_set$rating)
mu
```

The RMSE using only the overall average rating yields

```{r Movie factor 2, echo=FALSE}
RMSE_overall <- RMSE(mu,test_set$rating)
RMSE_overall
```

## 2.3 The *Movie* Effect Model

In addition to the overall average, this model incorporates the average rating of each movie title.

$$\ Y_u,_i =\mu+b_i+ \varepsilon_u,_i $$  

where 
$$b_i$$ 
is the factor of each movie *i*.

Typically, a model of this type would be built using a linear regression model such as 
```
lm(rating ~ as.factor(movieID), data = train_set)
```

However given that **movieID** yields more than 10,000 factors, such a model would be computationally intensive and not be feasible. Instead, each movie factor is approximated as the average of 
$$b_i = \ Y_u,_i-\mu$$

This approach leads to much faster computation.

```{r Movie factor 3, echo=FALSE}
#Ave by movie ID
m_ave <- train_set %>% 
  group_by(movieId) %>% 
  summarise(b_i=mean(rating - mu))
```

##### A histogram of the distribution of Movie Factor

```{r Movie factor plot, echo=FALSE}
m_ave %>% 
  ggplot(aes(x=b_i))+
  geom_histogram(bins=10,color="black",fill="blue")+
  ggtitle(expression(paste("Movie Factor (Ave Rating -" , hat(mu),")")))


pred_rat <- mu + test_set %>% 
  left_join(m_ave,by='movieId') %>% 
  pull(b_i)

```
 
 The RMSE incorporating the movie factor yields
 
```{r, echo=FALSE}
#RMSE by Movie ID
mod_1_rmse <- RMSE(pred_rat,test_set$rating)
mod_1_rmse
```



##### The *Overall Average* RMSE compared to the *Movie Effect* RMSE

```{r rmse table1, echo=FALSE}
#--------
#Results
rmse_res <- tibble(method = "Overall Average",
                   RMSE=RMSE_overall)
rmse_res <- bind_rows(rmse_res,
                      tibble(method = "Movie effect model",
                             RMSE=mod_1_rmse))

rmse_res
```

The results suggest increased accuracy with the inclusion the movie factor


## 2.4 The User and Movie Model

The model is further refined to include the average rating by user. 



$$\ Y_u,_i =\mu+b_i+b_u+ \varepsilon_u,_i $$  

where 
$$b_u$$ 
is the effect of user *u*.

Once again a standard linear regression model could be generated using

```
lm(rating ~ as.factor(movieID) + as.factor(userID), data = train_set)
```
In addition to 10,000 movieID factors, the userID factor adds an additional 70,000 factors, which once again would not generate a feasible model. 

In this case the user factor can be approximated as the average of
$$b_i = \ Y_u,_i-\mu - b_i$$

where
$$b_u$$
is the factor of user *u*.

The data used to approximate the user factor includes only users who submitted 100 or more ratings.

### A histogram of the distribution of user ratings 
```{r User Effect, echo=FALSE}
#-------
# User and Movie effect Model: Mu plus Movie and User factors

#Avg ratings by user with more than 100 ratings
train_set %>% 
  group_by(userId) %>% 
  summarise(b_u=mean(rating)) %>% 
  filter(n()>=100) %>% 
  ggplot(aes(b_u))+
  geom_histogram(color="black",fill="light blue")+
  ggtitle("UserId Factor")


#Ave by User ID
u_ave <- train_set %>% 
  left_join(m_ave, by="movieId") %>% 
  group_by(userId) %>% 
  summarise(b_u=mean(rating - mu - b_i))

pred_rat2 <-test_set %>% 
  left_join(m_ave,by='movieId') %>% 
  left_join(u_ave,by='userId') %>% 
  mutate(pred=mu + b_i + b_u) %>% 
  pull(pred)
```


The RMSE including the user effect yields
```{r RMSE users, echo=FALSE}
mod_2_rmse <- RMSE(pred_rat2,test_set$rating)
mod_2_rmse
```

which suggests even greater accuracy than the movie effect model.


# 3. Results

The results of the regression models yield the following results.

### A comparison of the RMSE of all three models

```{r RMSE results 2, echo=FALSE}
rmse_res <- bind_rows(rmse_res,
                      tibble(method = "User and Movie effect model",
                             RMSE=mod_2_rmse))
  
rmse_res

```

The RMSE values suggest that the accuracy of the models increase with the addition of the movieID and userID factors. 

An additional test using 25% of the original data set for validation yields

```
## # A tibble: 3 x 2
##   method                       RMSE
##   <chr>                       <dbl>
## 1 Overall Average             1.0595 
## 2 Movie effect model          0.94321
## 3 User and Movie effect model 0.86532
```

Which is consistent with the results using 25% of the data for validation, but is slightly less accurate.



# 4. Conclusion

As demonstrated, the RMSE totals suggest that the accuracy of the modified linear regression model increases with the addition of movie and user rating factors. The analysis could have been further expanded to see the effect of adding a factor for **genre** , **timestamp** or **release date**, which was not included in the original data set. 